{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 9.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.model_selection as skm\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import ISLP\n",
    "from ISLP.svm import plot as plot_svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 18)\n",
      "Index(['Purchase', 'WeekofPurchase', 'StoreID', 'PriceCH', 'PriceMM', 'DiscCH',\n",
      "       'DiscMM', 'SpecialCH', 'SpecialMM', 'LoyalCH', 'SalePriceMM',\n",
      "       'SalePriceCH', 'PriceDiff', 'Store7', 'PctDiscMM', 'PctDiscCH',\n",
      "       'ListPriceDiff', 'STORE'],\n",
      "      dtype='object')\n",
      "Purchase           object\n",
      "WeekofPurchase      int64\n",
      "StoreID             int64\n",
      "PriceCH           float64\n",
      "PriceMM           float64\n",
      "DiscCH            float64\n",
      "DiscMM            float64\n",
      "SpecialCH           int64\n",
      "SpecialMM           int64\n",
      "LoyalCH           float64\n",
      "SalePriceMM       float64\n",
      "SalePriceCH       float64\n",
      "PriceDiff         float64\n",
      "Store7             object\n",
      "PctDiscMM         float64\n",
      "PctDiscCH         float64\n",
      "ListPriceDiff     float64\n",
      "STORE               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = ISLP.load_data(\"OJ\")\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are categorial variables in the data set, so I will convert them to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=\"Purchase\")\n",
    "X = pd.get_dummies(X)\n",
    "y = data[\"Purchase\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test separation as instructed in the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X.iloc[:800]\n",
    "y_test = y.iloc[:800]\n",
    "X_train = X.iloc[800:]\n",
    "y_train = y.iloc[800:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the follwing $f_1$ metrics will be used to score the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_f1_scorer = make_scorer(f1_score, pos_label=\"CH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the results will be saved in a data frame, here is a short function to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults = pd.DataFrame()\n",
    "def storeResults(model, comment=\"\"):\n",
    "    global dfResults\n",
    "    df_ = pd.DataFrame({\n",
    "        \"C\":model.get_params()[\"C\"],\n",
    "        \"kernel\":model.get_params()[\"kernel\"],\n",
    "        \"test_score\": f1_score(y_test, model.predict(X_test), pos_label = \"CH\"),\n",
    "        \"train_score\": f1_score(y_train, model.predict(X_train), pos_label = \"CH\"),\n",
    "        \"n_support\": model.support_vectors_.shape[0],\n",
    "        \"comment\":comment\n",
    "        }, index = [0])\n",
    "    dfResults = pd.concat([dfResults, df_]).drop_duplicates()\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b), (c) Linear Kernel witj C = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel to use was not specified in the assignment, to I will use linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 # of support vectors:  205\n",
      " F1 score: Train: 0.700, Test: 0.614\n"
     ]
    }
   ],
   "source": [
    "kernel_ = \"linear\"\n",
    "model = svm.SVC(C=0.01, kernel=kernel_)\n",
    "model.fit(X_train, y_train)\n",
    "storeResults(model)\n",
    "\n",
    "print(\"C = \", model.get_params()[\"C\"], \"# of support vectors: \", model.support_vectors_.shape[0])\n",
    "print(\" F1 score: Train: {:.3f}, Test: {:.3f}\".format( \n",
    "    f1_score(y_train, model.predict(X_train), pos_label=\"CH\"), \n",
    "    f1_score(y_test, model.predict(X_test), pos_label=\"CH\")\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies are reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason my system hangs when I am using CV with C>4, so only values up to 3 will be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'C': [0.01, 0.1, 1, 1.5, 2, 2.5, 3]\n",
    "}\n",
    "model = svm.SVC(kernel=kernel_)\n",
    "grid = GridSearchCV(model, grid_params, cv = 5, scoring=my_f1_scorer)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, C=1 was selected to give optimal score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  1 # of support vectors:  142\n",
      " F1 score: Train: 0.840, Test: 0.873\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(C=grid.best_params_[\"C\"], kernel=kernel_)\n",
    "model.fit(X_train, y_train)\n",
    "storeResults(model, comment=\"bestGrid\")\n",
    "print(\"C = \", model.get_params()[\"C\"], \"# of support vectors: \", model.support_vectors_.shape[0])\n",
    "print(\" F1 score: Train: {:.3f}, Test: {:.3f}\".format( \n",
    "    f1_score(y_train, model.predict(X_train), pos_label=\"CH\"), \n",
    "    f1_score(y_test, model.predict(X_test), pos_label=\"CH\")\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time score is even better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Radial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 # of support vectors:  228\n",
      " F1 score: Train: 0.732, Test: 0.766\n"
     ]
    }
   ],
   "source": [
    "kernel_ = \"rbf\"\n",
    "model = svm.SVC(C=0.01, kernel=kernel_)\n",
    "modelR = model\n",
    "model.fit(X_train, y_train)\n",
    "storeResults(model)\n",
    "print(\"C = \", model.get_params()[\"C\"], \"# of support vectors: \", model.support_vectors_.shape[0])\n",
    "print(\" F1 score: Train: {:.3f}, Test: {:.3f}\".format( \n",
    "    f1_score(y_train, model.predict(X_train), pos_label=\"CH\"), \n",
    "    f1_score(y_test, model.predict(X_test), pos_label=\"CH\")\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RBF kernel there are no problems with high $C$, we will check some values up to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'C': [0.01, 0.1, 1, 1.5, 2, 2.5, 3, 4, 8, 10]\n",
    "}\n",
    "model = svm.SVC(kernel=kernel_)\n",
    "grid = GridSearchCV(model, grid_params, cv = 5, scoring=my_f1_scorer)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal parameter is on the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 # of support vectors:  228\n",
      " F1 score: Train: 0.732, Test: 0.766\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(C=grid.best_params_[\"C\"], kernel=kernel_)\n",
    "model.fit(X_train, y_train)\n",
    "storeResults(model, comment=\"bestGrid\")\n",
    "print(\"C = \", model.get_params()[\"C\"], \"# of support vectors: \", model.support_vectors_.shape[0])\n",
    "print(\" F1 score: Train: {:.3f}, Test: {:.3f}\".format( \n",
    "    f1_score(y_train, model.predict(X_train), pos_label=\"CH\"), \n",
    "    f1_score(y_test, model.predict(X_test), pos_label=\"CH\")\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model optimal accuracy is better then first linear, but smaller then optimal linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider polynomial with `degree=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 # of support vectors:  228\n",
      " F1 score: Train: 0.732, Test: 0.766\n"
     ]
    }
   ],
   "source": [
    "kernel_ = \"poly\"\n",
    "model = svm.SVC(C=0.01, kernel=kernel_, degree=2)\n",
    "modelP = model\n",
    "modelP.fit(X_train, y_train)\n",
    "storeResults(modelP)\n",
    "print(\"C = \", modelP.get_params()[\"C\"], \"# of support vectors: \", model.support_vectors_.shape[0])\n",
    "print(\" F1 score: Train: {:.3f}, Test: {:.3f}\".format( \n",
    "    f1_score(y_train, model.predict(X_train), pos_label=\"CH\"), \n",
    "    f1_score(y_test, model.predict(X_test), pos_label=\"CH\")\n",
    "    ))\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, results are exactly the same as in the case of RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again no problems with high C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'C': [0.01, 0.1, 1, 1.5, 2, 2.5, 3, 4, 8, 10]\n",
    "}\n",
    "model = svm.SVC(kernel=kernel_, degree= 2)\n",
    "grid = GridSearchCV(model, grid_params, cv = 5, scoring=my_f1_scorer)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, C=0.01 was selected to give optimal score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 # of support vectors:  228\n",
      " F1 score: Train: 0.732, Test: 0.766\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(C=grid.best_params_[\"C\"], kernel=kernel_, degree = 2)\n",
    "model.fit(X_train, y_train)\n",
    "storeResults(model, comment=\"bestGrid\")\n",
    "print(\"C = \", model.get_params()[\"C\"], \"# of support vectors: \", model.support_vectors_.shape[0])\n",
    "print(\" F1 score: Train: {:.3f}, Test: {:.3f}\".format( \n",
    "    f1_score(y_train, model.predict(X_train), pos_label=\"CH\"), \n",
    "    f1_score(y_test, model.predict(X_test), pos_label=\"CH\")\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that in this case SVM with linear kernel and C=1 gives the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>kernel</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>n_support</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.873494</td>\n",
       "      <td>0.840125</td>\n",
       "      <td>142</td>\n",
       "      <td>bestGrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.766384</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>228</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.766384</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>228</td>\n",
       "      <td>bestGrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.766384</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>228</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.766384</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>228</td>\n",
       "      <td>bestGrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.614057</td>\n",
       "      <td>0.699647</td>\n",
       "      <td>205</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  kernel  test_score  train_score  n_support   comment\n",
       "0  1.00  linear    0.873494     0.840125        142  bestGrid\n",
       "0  0.01     rbf    0.766384     0.732394        228          \n",
       "0  0.01     rbf    0.766384     0.732394        228  bestGrid\n",
       "0  0.01    poly    0.766384     0.732394        228          \n",
       "0  0.01    poly    0.766384     0.732394        228  bestGrid\n",
       "0  0.01  linear    0.614057     0.699647        205          "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResults.sort_values(\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that both `RBF` and `Poly` kernels give exactly the same result.\n",
    "\n",
    "It is easy to check that their presictions are the same both on train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "np.all(modelR.predict(X_train) == modelP.predict(X_train)),\n",
    "np.all(modelR.predict(X_test) == modelP.predict(X_test))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual models, however, are different. For example, they are using different sets of support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(\n",
    "    np.sort(modelR.support_) == np.sort(modelP.support_)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7200",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
