[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Support Vector Machine",
    "section": "",
    "text": "(ns index)\n\n\n1 Support Vector Machines\n\n1.0.1 Assignment Setup\n\nCreate a new repository on Gitlab.com. The repository MUST be named following the convention: CS[AAAA]_[XX][YYYY]_A[ZZ]_G[NN] where [AAAA] is replaced by the four digit course number (if this is a cross-listed 4000/5000 level course, use the 4000 level number), [XX] is replaced with the semester (FA, SP, or SU), [YYYY] is replaced with the four digit year, [ZZ] is replaced with the two digit assignment number, [NN] is replaced with the two digit group number, and [LASTNAME] is replaced with your last name. Assignments that are misnamed will be given 0 credit!\nYou may work in a group of 1 if you choose.\nAdd greenr@bgsu.edu and the TA (if there is one) to your project with Maintainer project access\nSetup your project appropriately for this assignment:\nA README.md file in the root of the project\nA Jupyter notebook or main file that contains all of your work in a clear and understandable manner.\nYou may work by yourself or in a group of 2. if working in a group of 2, each student should perform the implementation and analysis of a single algorithm.\n\n\n\n1.0.2 Instructions\n\nIn a Jupyter notebook using Python, complete exercise 9.5, 9.7, and 9.8 (Applied) from Introduction to Statistical Learning with Applications in Python.\nModify the “README.md” file to include responses as indicated by each question.\nMake sure that your README file is formatted properly and is visually appealing. It should be free of grammatical errors, punctuation errors, capitalization issues, etc. Sentences should be complete\n\n\nsource: src/index.clj",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Support Vector Machines</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html",
    "href": "assignment.islp_9_5.html",
    "title": "2  ISLP Ch9 Q5",
    "section": "",
    "text": "2.1 Generate Data\n_unnamed [5 3]:\n_unnamed: descriptive-stats [3 11]:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#generate-data",
    "href": "assignment.islp_9_5.html#generate-data",
    "title": "2  ISLP Ch9 Q5",
    "section": "",
    "text": "(defn generate-data [len]\n  (let [rng (r/rng :isaac 0)\n        x1 (map #(- % 0.5)\n                (r/-&gt;seq (r/distribution :uniform-real {:rng rng}) len))\n        x2 (map #(- % 0.5)\n                (r/-&gt;seq (r/distribution :uniform-real {:rng rng}) len))\n        y-int (map #(&gt; (- (Math/pow %1 2) (Math/pow %2 2)) 0) x1 x2)\n        y (map {false 0 true 1} y-int)]\n    {:x1 x1 :x2 x2 :y y}))\n\n\n(def data\n  (tc/dataset (generate-data 500)))\n\n\n(tc/head data)\n\n\n\n\n\n:x1\n:x2\n:y\n\n\n\n\n0.42144632\n-0.13972611\n1\n\n\n-0.13155138\n0.12495964\n1\n\n\n-0.06103313\n0.28605361\n0\n\n\n0.18657268\n-0.04808715\n1\n\n\n-0.35271109\n-0.22763962\n1\n\n\n\n\n(tc/info data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:col-name\n:datatype\n:n-valid\n:n-missing\n:min\n:mean\n:max\n:standard-deviation\n:skew\n:first\n:last\n\n\n\n\n:x1\n:float64\n500\n0\n-0.49734823\n0.00563017\n0.49996755\n0.28662407\n-0.03626498\n0.42144632\n0.37330638\n\n\n:x2\n:float64\n500\n0\n-0.49909375\n0.00879174\n0.49911608\n0.28692970\n-0.03754993\n-0.13972611\n0.33195477\n\n\n:y\n:int64\n500\n0\n0.00000000\n0.50200000\n1.00000000\n0.50049675\n-0.00802416\n1.00000000\n1.00000000\n\n\n\n\nPlot the observations, colored according to their class labels. Your plot should display X1 on the x-axis, and X2 on the y-axis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#plot-data",
    "href": "assignment.islp_9_5.html#plot-data",
    "title": "2  ISLP Ch9 Q5",
    "section": "2.2 Plot data",
    "text": "2.2 Plot data\n\n^kind/vega-lite\n(let [plot (tc/rows data :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\n(comment\n  ;wont plot when rendered\n  (-&gt; data\n      (hanami/plot ht/point-chart\n                   {:X     :x1\n                    :Y     :x2\n                    :MSIZE 75\n                    :COLOR \"y\"\n                    :CTYPE \"nominal\"})))\n\n\nFit a logistic regression model to the data, using X1 and X2 as predictors.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#logistic-regression",
    "href": "assignment.islp_9_5.html#logistic-regression",
    "title": "2  ISLP Ch9 Q5",
    "section": "2.3 Logistic regression",
    "text": "2.3 Logistic regression\n\n(def response :y)\n\n\n(def regressors\n  (tc/column-names data (complement #{response})))\n\n\n2.3.1 Model task\nPipeline-vanilla in case want to do more in the ingestion.\n\n(def pipeline-vanilla\n  (morph/pipeline\n    (dsm/categorical-&gt;number [response])\n    (dsm/set-inference-target response)))\n\nAdd model context to ingestion.\n\n(defn- create-model-pipeline\n  [pipeline-fn model-type params]\n  (morph/pipeline\n    pipeline-fn\n    {:metamorph/id :model}\n    (ml/model (merge {:model-type model-type} params))))\n\n\n#'assignment.islp-9-5/create-model-pipeline\n\n\n2.3.1.1 Logistic model\n\n(defn logistic-pipe-fn\n  [pipeline-fn params]\n  (create-model-pipeline pipeline-fn :smile.classification/logistic-regression params))\n\n\n\n\n2.3.2 Evaluate chain\n\n(defn train-test [dataset]\n  (tc/split-&gt;seq dataset :bootstrap {:seed 123 :repeats 20}))\n\n\n(defn train-val [dataset]\n  (let [ds-split (train-test dataset)]\n    (tc/split-&gt;seq (:train (first ds-split)) :kfold {:seed 123 :k 5})))\n\n\n2.3.2.1 Hyperparameter-grid\n\n(comment\n  (ml/hyperparameters :smile.classification/logistic-regression))\n\n\n(defn generate-hyperparams [model-type]\n  (case model-type\n    :logistic (take 100\n                    (grid/sobol-gridsearch\n                      (ml/hyperparameters :smile.classification/logistic-regression)))))\n\n\n\n2.3.2.2 Work-horse\n\n(defn evaluate-pipe [pipe data]\n  (ml/evaluate-pipelines\n    pipe\n    data\n    stats/cohens-kappa\n    :accuracy\n    {:other-metrices                   [{:name      :mathews-cor-coef\n                                         :metric-fn stats/mcc}\n                                        {:name      :accuracy\n                                         :metric-fn loss/classification-accuracy}]\n     :return-best-pipeline-only        false\n     :return-best-crossvalidation-only true}))\n\n\n(defn evaluate-model [dataset split-fn model-type model-fn pipeline-fn]\n  (let [data-split (split-fn dataset)\n        pipelines (map (partial model-fn pipeline-fn) (generate-hyperparams model-type))]\n    (evaluate-pipe pipelines data-split)))\n\nchange for different models to test\n\n(def model-type-fns\n  {:logistic logistic-pipe-fn})\n\n\n(defn evaluate-models [dataset split-fn pipeline-fn]\n  (mapv (fn [[model-type model-fn]]\n          (evaluate-model dataset split-fn model-type model-fn pipeline-fn))\n        model-type-fns))\n\n\n(comment\n  ; Alternative: if want to expand `model-type-fns` to simplify `evaluate-models`\n  (def model-type-fns\n    {:logistic [logistic-pipe-fn pipeline-vanilla]})\n\n  (defn evaluate-model [dataset split-fn model-type model-and-pipeline]\n    (let [[model-fn pipeline-fn] model-and-pipeline\n          data-split (split-fn dataset)\n          pipelines (map (partial model-fn pipeline-fn) (generate-hyperparams model-type))]\n      (evaluate-pipe pipelines data-split)))\n\n  (defn evaluate-models [dataset split-fn]\n    (mapv (fn [[model-type model-and-pipeline]]\n            (evaluate-model dataset split-fn model-type model-and-pipeline))\n          model-type-fns))\n\n  (def logistic-models (evaluate-models data train-test)))\n\n\n\n\n2.3.3 View model/s\n\n(defn best-models [eval]\n  (-&gt;&gt; eval\n       flatten\n       (map\n         #(hash-map :summary (ml/thaw-model (get-in % [:fit-ctx :model]))\n                    :fit-ctx (:fit-ctx %)\n                    :timing-fit (:timing-fit %)\n                    :metric ((comp :metric :test-transform) %)\n                    :other-metrices ((comp :other-metrices :test-transform) %)\n                    :other-metric-1 ((comp :metric first) ((comp :other-metrices :test-transform) %))\n                    :other-metric-2 ((comp :metric second) ((comp :other-metrices :test-transform) %))\n                    :params ((comp :options :model :fit-ctx) %)\n                    :pipe-fn (:pipe-fn %)))\n       (sort-by :metric)))\n\n\n\n2.3.4 Get model/s\n\n(comment\n  (def logistic-models (evaluate-models data train-test pipeline-vanilla))\n\n  (def logistic-model\n    (-&gt; logistic-models\n        best-models\n        reverse))\n\n  (-&gt; logistic-model first :summary)\n  (-&gt; logistic-model first :metric)\n  (-&gt; logistic-model first :other-metrices)\n  (-&gt; logistic-model first :params)\n  ;=&gt;\n  ;{:model-type :smile.classification/logistic-regression,\n  ; :lambda 79.31055172413794,\n  ; :tolerance 1.0E-9,\n  ; :max-iterations 9478}\n  (-&gt; logistic-model first :fit-ctx :model :options))\n\n\n(def params\n  {:model-type :smile.classification/logistic-regression,\n     :lambda 79.31055172413794,\n     :tolerance 1.0E-9,\n     :max-iterations 9478})\n\n\n(def logistic-model\n  (first (evaluate-pipe\n           (map (partial logistic-pipe-fn pipeline-vanilla) params)\n           (train-test data))))\n\n\nApply this model to the training data in order to obtain a predicted class label for each training observation. Plot the observations, colored according to the predicted class labels. The decision boundary should be linear.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#visualize-model-fit",
    "href": "assignment.islp_9_5.html#visualize-model-fit",
    "title": "2  ISLP Ch9 Q5",
    "section": "2.4 Visualize model fit",
    "text": "2.4 Visualize model fit\nFunction to get the best model’s training data.\n\n(defn model-&gt;data [model]\n  (let [processed-data (-&gt; model first :fit-ctx :model :model-data :smile-df-used)\n        keys-vec (-&gt; data\n                     (morph/pipe-it (-&gt; model first :pipe-fn))\n                     keys)\n        without-y (vec (remove #(= :y %) keys-vec))\n        with-y-at-end (conj without-y :y)\n        data-map (zipmap with-y-at-end processed-data)]\n    (tc/dataset data-map)))\n\n\n(def predictions\n  (-&gt; (model-&gt;data logistic-model)\n      (morph/transform-pipe\n        (-&gt; logistic-model first :pipe-fn)\n        (-&gt; logistic-model first :fit-ctx))\n      :metamorph/data\n      :y\n      vec))\n\n\n(def data-predict\n  (tc/add-or-replace-column (model-&gt;data logistic-model) :y predictions))\n\n\n^kind/vega-lite\n(let [plot (tc/rows data-predict :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\n2.4.1 Model performance\nFunctions to view performance on full data.\n\n(defn preds\n  [model]\n  (-&gt; data\n      (morph/transform-pipe\n        (-&gt; model first :pipe-fn)\n        (-&gt; model first :fit-ctx))\n      :metamorph/data\n      :y\n      (-&gt;&gt; (map #(long %))\n           vec)))\n\n\n(defn actual\n  [model]\n  (-&gt; data\n      (morph/fit-pipe\n        (-&gt; model first :pipe-fn))\n      :metamorph/data\n      :y\n      vec))\n\n\n(defn evaluate-predictions\n  \"Evaluates predictions against actual labels, returns confusion map and metrics.\"\n  [preds actual]\n  (let [conf-map (mlc/confusion-map-&gt;ds (mlc/confusion-map preds actual :none))\n        kappa (stats/cohens-kappa preds actual)\n        mcc (stats/mcc preds actual)]\n    {:confusion-map conf-map\n     :cohens-kappa  kappa\n     :mcc           mcc}))\n\n\n^kind/dataset\n(evaluate-predictions (preds logistic-model) (actual logistic-model))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n235\n14\n\n\n1\n174\n77\n\n\n\n, :cohens-kappa 0.2499082334540928, :mcc 0.3246722267851866}\n\nNow fit a logistic regression model to the data using non-linear functions of X\\(_1\\) and X\\(_2\\) as predictors (e.g. \\(X_1^2\\), \\(X_1*X_2\\), \\(log(X_2)\\), and so forth)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#non-linear-regressors",
    "href": "assignment.islp_9_5.html#non-linear-regressors",
    "title": "2  ISLP Ch9 Q5",
    "section": "2.5 Non-linear regressors",
    "text": "2.5 Non-linear regressors\nMaking pipelines (like vanilla) to apply to evaluate-models\n\n(def pipeline-squared\n  (morph/pipeline\n    (tcm/add-or-replace-columns {:x1-sq (fn [row]\n                                          (map #(Math/pow % 2) (:x1 row)))\n                                 :x2-sq (fn [row]\n                                          (map #(Math/pow % 2) (:x2 row)))})\n    (dsm/categorical-&gt;number [response])\n    (dsm/set-inference-target response)))\n\n\n(def pipeline-interact\n  (morph/pipeline\n    (tcm/add-or-replace-columns {:x1-x2 (fn [ds] (dfn/* (:x1 ds)\n                                                        (:x2 ds)))})\n    (dsm/categorical-&gt;number [response])\n    (dsm/set-inference-target response)))\n\n\n(def pipeline-combined\n  (morph/pipeline\n    (tcm/add-or-replace-columns {:x1-x2 (fn [ds] (dfn/* (:x1 ds)\n                                                        (:x2 ds)))\n                                 :x1-sq (fn [row]\n                                          (map #(Math/pow % 2) (:x1 row)))\n                                 :x2-sq (fn [row]\n                                          (map #(Math/pow % 2) (:x2 row)))})\n    (dsm/categorical-&gt;number [response])\n    (dsm/set-inference-target response)))\n\n\n2.5.1 Set the model case name and respective model pipeline\n\n(def model-type-fns\n  {:logistic logistic-pipe-fn})\n\n\n(comment\n  (def pipe-squared\n    (evaluate-models data train-test pipeline-squared))\n  (def pipe-interact\n    (evaluate-models data train-test pipeline-interact))\n  (def pipe-combined\n  (evaluate-models data train-test pipeline-combined)))\n\nDon’t want to run the full evaluate models Squared\n\n(def params\n  {:model-type :smile.classification/logistic-regression,\n   :lambda 0.001,\n   :tolerance 0.07894736863157896,\n   :max-iterations 3747})\n\n\n(def pipe-squared\n  (first (evaluate-pipe\n           (map (partial logistic-pipe-fn pipeline-squared) params)\n           (train-test data))))\n\n\n(def logistic-squared\n  (-&gt; pipe-squared best-models reverse))\n\n\n(-&gt; logistic-squared first :fit-ctx :model :feature-columns)\n\n\n[:x1 :x2 :x1-sq :x2-sq]\n\nInteract\n\n(def params\n  {:model-type :smile.classification/logistic-regression,\n   :lambda 41.37989655172413,\n   :tolerance 1.0E-9,\n   :max-iterations 4268})\n\n\n(def pipe-interact\n  (first (evaluate-pipe\n           (map (partial logistic-pipe-fn pipeline-interact) params)\n           (train-test data))))\n\n\n(def logistic-interact\n  (-&gt; pipe-interact best-models reverse))\n\n\n(-&gt; logistic-interact first :fit-ctx :model :feature-columns)\n\n\n[:x1 :x2 :x1-x2]\n\nCombined\n\n(def params\n  {:model-type :smile.classification/logistic-regression,\n   :lambda 0.001,\n   :tolerance 0.07894736863157896,\n   :max-iterations 3747}  )\n\n\n(def pipe-combined\n  (first (evaluate-pipe\n           (map (partial logistic-pipe-fn pipeline-combined) params)\n           (train-test data))))\n\n\n(def logistic-combined\n  (-&gt; pipe-combined best-models reverse))\n\n\n(-&gt; logistic-combined first :fit-ctx :model :feature-columns)\n\n\n[:x1 :x2 :x1-x2 :x1-sq :x2-sq]\n\n\n^kind/dataset\n(evaluate-predictions (preds logistic-squared) (actual logistic-squared))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n240\n9\n\n\n1\n0.000\n251\n\n\n\n, :cohens-kappa 0.9639942390782525, :mcc 0.964619715510437}\n\n^kind/dataset\n(evaluate-predictions (preds logistic-interact) (actual logistic-interact))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n191\n58\n\n\n1\n123\n128\n\n\n\n, :cohens-kappa 0.27674061760756985, :mcc 0.28657584572643147}\n\n^kind/dataset\n(evaluate-predictions (preds logistic-combined) (actual logistic-combined))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n249\n0.000\n\n\n1\n5\n246\n\n\n\n, :cohens-kappa 0.9800012799180852, :mcc 0.98019731389307}\n\nApply this model to the training data in order to obtain a predicted class label for each training observation. Plot the observations, colored according to the predicted class labels. The decision boundary should be obviously non-linear. If it is not, then repeat (a)–(e) until you come up with an example in which the predicted class labels are obviously non-linear.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#non-linear-logistic-visualization",
    "href": "assignment.islp_9_5.html#non-linear-logistic-visualization",
    "title": "2  ISLP Ch9 Q5",
    "section": "2.6 Non-linear logistic visualization",
    "text": "2.6 Non-linear logistic visualization\n\n(def data-plot\n  (tc/add-or-replace-column data :y (preds logistic-interact)))\n\n\n^kind/vega-lite\n(let [plot (tc/rows data-plot :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\n(def data-plot\n  (tc/add-or-replace-column data :y (preds logistic-squared)))\n\n\n^kind/vega-lite\n(let [plot (tc/rows data-plot :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\nFit a support vector classifer to the data with X1 and X2 as predictors. Obtain a class prediction for each training observation. Plot the observations, colored according to the predicted class labels.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#support-vector-visualization",
    "href": "assignment.islp_9_5.html#support-vector-visualization",
    "title": "2  ISLP Ch9 Q5",
    "section": "2.7 Support vector visualization",
    "text": "2.7 Support vector visualization\nMany issues with sklearn. One of which, major parameter “C” cost, does not work.\n\n(comment\n  ;failed a lot, checked and found \"c\" cant be param, strange\n  (def svm-pipe\n    (morph/pipeline\n      (dsm/categorical-&gt;number [response])\n      (dsm/set-inference-target response)\n      {:metamorph/id :model}\n      (ml/model {:model-type     :sklearn.classification/svc\n                 :kernel         \"poly\"\n                 :degree         7\n                 ;:c 0.001 ;doesnt work with c???\n                 :predict-proba? false})))\n\n  (def ds-split\n    (tc/split-&gt;seq data :bootstrap {:seed 123 :repeats 20}))\n\n  (evaluate-pipe [svm-pipe] ds-split))\n\n\n2.7.1 SVM context pipeline\nLike the logistic pipeline context.\n\n(defn svm-pipe-fn\n  [pipeline-fn params]\n  (create-model-pipeline pipeline-fn :sklearn.classification/svc params))\n\n\n(comment ;nil\n  (ml/hyperparameters :sklearn.classification/svc))\n\n\n\n2.7.2 Set the model case name and respective model pipeline\n\n(defn generate-hyperparams [model-type]\n  (case model-type\n    :svm-linear (grid/sobol-gridsearch\n                  {:kernel         \"linear\"\n                   :predict-proba? false})\n    :svm-rbf (grid/sobol-gridsearch\n               {:predict-proba? false})\n    :svm-sigmoid (grid/sobol-gridsearch\n                   {:kernel         \"sigmoid\"\n                    :predict-proba? false})\n    :svm-poly (grid/sobol-gridsearch\n                {:kernel         \"poly\"\n                 :degree         (grid/linear 1 4 4 :int32)\n                 :predict-proba? false})))\n\n\n(def model-type-fns\n  {:svm-linear  svm-pipe-fn\n   :svm-rbf     svm-pipe-fn\n   :svm-sigmoid svm-pipe-fn\n   :svm-poly    svm-pipe-fn})\n\n\n\n2.7.3 Collect all four SVM models.\n\n(def svm-models (evaluate-models data train-test pipeline-vanilla))\n\n\n\n2.7.4 Extract first for the `:svm-linear.\n\n(def svm-linear\n  (-&gt; svm-models first best-models reverse))\n\n\n(-&gt; svm-linear first :fit-ctx :model :options)\n\n\n{:model-type :sklearn.classification/svc,\n :kernel \"linear\",\n :predict-proba? false}\n\n\n^kind/dataset\n(evaluate-predictions (preds svm-linear) (actual svm-linear))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n159\n90\n\n\n1\n121\n130\n\n\n\n, :cohens-kappa 0.1564049256356948, :mcc 0.15762023273027012}\n\n(def data-plot\n  (tc/add-or-replace-column data :y (preds svm-linear)))\n\n\n^kind/vega-lite\n(let [plot (tc/rows data-plot :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\nFit a SVM using a non-linear kernel to the data. Obtain a class prediction for each training observation. Plot the observations,colored according to the predicted class labels",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_5.html#non-linear-kernels",
    "href": "assignment.islp_9_5.html#non-linear-kernels",
    "title": "2  ISLP Ch9 Q5",
    "section": "2.8 Non-linear kernels",
    "text": "2.8 Non-linear kernels\nAlready made in the last question, now extract from the svm-models collection.\n\n(def svm-rbf\n  (-&gt; svm-models second best-models reverse))\n\n\n(-&gt; svm-rbf first :fit-ctx :model :options)\n\n\n{:model-type :sklearn.classification/svc, :predict-proba? false}\n\n\n(def data-plot\n  (tc/add-or-replace-column data :y (preds svm-rbf)))\n\n\n^kind/vega-lite\n(let [plot (tc/rows data-plot :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\n^kind/dataset\n(evaluate-predictions (preds svm-rbf) (actual svm-rbf))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n236\n13\n\n\n1\n1\n250\n\n\n\n, :cohens-kappa 0.943988349576712, :mcc 0.9450781610261636}\n\n(def svm-sigmoid\n  (-&gt; svm-models rest second best-models reverse))\n\n\n(-&gt; svm-sigmoid first :fit-ctx :model :options)\n\n\n{:model-type :sklearn.classification/svc,\n :kernel \"sigmoid\",\n :predict-proba? false}\n\n\n(def data-plot\n  (tc/add-or-replace-column data :y (preds svm-sigmoid)))\n\n\n^kind/vega-lite\n(let [plot (tc/rows data-plot :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\n^kind/dataset\n(evaluate-predictions (preds svm-sigmoid) (actual svm-sigmoid))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n127\n122\n\n\n1\n98\n153\n\n\n\n, :cohens-kappa 0.11964785914365761, :mcc 0.120203484336723}\n\n(def svm-poly\n  (-&gt; svm-models last best-models reverse))\n\n\n(-&gt; svm-poly first :fit-ctx :model :options)\n\n\n{:model-type :sklearn.classification/svc,\n :kernel \"poly\",\n :degree 2,\n :predict-proba? false}\n\n\n(def data-plot\n  (tc/add-or-replace-column data :y (preds svm-poly)))\n\n\n^kind/vega-lite\n(let [plot (tc/rows data-plot :as-maps)]\n  {:data     {:values plot}\n   :mark     \"circle\"\n   :encoding {:x     {:field :x1 :type \"quantitative\"}\n              :y     {:field :x2 :type \"quantitative\"}\n              :color {:field :y :type \"nominal\"}}})\n\n\n\n^kind/dataset\n(evaluate-predictions (preds svm-poly) (actual svm-poly))\n\n{:confusion-map _unnamed [3 3]:\n\n\n\n:column-name\n0\n1\n\n\n\n\ncolumn-name\n0\n1\n\n\n0\n248\n1\n\n\n1\n3\n248\n\n\n\n, :cohens-kappa 0.984000255995904, :mcc 0.984031744507912}\n\nComment on your results.\n\n\nsource: src/assignment/islp_9_5.clj",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ISLP Ch9 Q5</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_7.html",
    "href": "assignment.islp_9_7.html",
    "title": "3  ISLP Ch9 Q7",
    "section": "",
    "text": "3.1 Binary response\nLoad the required R libraries\nCall in datasets from R. This one comes from the islr library in a dataset called Auto.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ISLP Ch9 Q7</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_7.html#binary-response",
    "href": "assignment.islp_9_7.html#binary-response",
    "title": "3  ISLP Ch9 Q7",
    "section": "",
    "text": "(require-r '[base :refer [RNGkind set-seed summary plot $ expand-grid which-max subset\n                          as-numeric factor levels as-character data-frame append]]\n           '[stats :refer [predict]]\n           '[ISLR :as islr]\n           '[caret :refer [createDataPartition trainControl modelLookup train\n                           defaultSummary prSummary twoClassSummary mnLogLoss]]\n           '[kernlab]\n           '[e1071]\n           '[ggplot2 :refer [ggplot aes geom_point geom_line\n                             facet_wrap theme_bw]])\n\n\nnil\n\n\n\n(def auto\n  (-&gt; (r-&gt;clj islr/Auto)\n      (tc/drop-columns :$row.names)))\n\n\n(stats/median (:mpg auto))\n\n\n22.75\n\n\n3.1.1 Create binary response\n\n(def auto-cat\n  (-&gt; auto\n      (tc/map-columns :mpg-cat [:mpg]\n                      #(if (&gt;= % (stats/median (:mpg auto))) 1 0))\n      (tc/map-columns :mpg-cat str)))\n\nLater, working with the data, R doesn’t like :keywords like Clojure does. Create a R-compatible data.frame. Notice, I’m flipping through both Clojure and R data structures in R functions and vice cersa.\n\n(def r-data\n  (tc/rename-columns auto-cat (fn [col]\n                                (-&gt; col\n                                    name\n                                    (clojure.string/replace #\"-\" \".\")))))\n\n\n(keys auto-cat)\n\n\n(:mpg\n :cylinders\n :displacement\n :horsepower\n :weight\n :acceleration\n :year\n :origin\n :name\n :mpg-cat)\n\n\n(keys r-data)\n\n\n(\"mpg\"\n \"cylinders\"\n \"displacement\"\n \"horsepower\"\n \"weight\"\n \"acceleration\"\n \"year\"\n \"origin\"\n \"name\"\n \"mpg.cat\")\n\n\n(summary auto-cat)\n\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.00   1st Qu.:4.000   1st Qu.:105.0   1st Qu.: 75.0   1st Qu.:2225  \n Median :22.75   Median :4.000   Median :151.0   Median : 93.5   Median :2804  \n Mean   :23.45   Mean   :5.472   Mean   :194.4   Mean   :104.5   Mean   :2978  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:275.8   3rd Qu.:126.0   3rd Qu.:3615  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                                               \n  acceleration        year           origin                    name    \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   amc matador     :  5  \n 1st Qu.:13.78   1st Qu.:73.00   1st Qu.:1.000   ford pinto      :  5  \n Median :15.50   Median :76.00   Median :1.000   toyota corolla  :  5  \n Mean   :15.54   Mean   :75.98   Mean   :1.577   chevrolet impala:  4  \n 3rd Qu.:17.02   3rd Qu.:79.00   3rd Qu.:2.000   amc hornet      :  4  \n Max.   :24.80   Max.   :82.00   Max.   :3.000   ford maverick   :  4  \n                                                 (Other)         :365  \n   mpg-cat         \n Length:392        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\n\nFit a support vector classifier to the data with various values of C, in order to predict whether a car gets high or low gas mileage. Report the cross-validation errors associated with different values of this parameter. Comment on your results. Note you will need to fit the classifier without the gas mileage variable to produce sensible results",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ISLP Ch9 Q7</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_7.html#fit-svms",
    "href": "assignment.islp_9_7.html#fit-svms",
    "title": "3  ISLP Ch9 Q7",
    "section": "3.2 Fit SVMs",
    "text": "3.2 Fit SVMs\nPartition data\n\n(def index\n  (createDataPartition :y ($ r-data 'mpg.cat)\n                       :p 0.7 :list false))\n\nTrain and test data\n\n(def training-data\n  (bra r-data index nil))\n\n\n(def test-data\n  (bra r-data (r- index) nil))\n\nCaret svmLinear\n\n(RNGkind :sample.kind \"Rounding\")\n\n\n[1] \"Mersenne-Twister\" \"Inversion\"        \"Rounding\"        \n\n\n\n(set-seed 0)\n\n\nNULL\n\n\nBootstrap cross-validation\n\n(def train-control\n  (trainControl :method \"boot\" :number 20))\n\n\n(modelLookup \"svmLinear\")\n\n\n      model parameter label forReg forClass probModel\n1 svmLinear         C  Cost   TRUE     TRUE      TRUE\n\n\nBuild model\n\n(def svm-linear\n  (train '(tilde mpg.cat (- . mpg))\n         :data training-data :method \"svmLinear\"\n         :trControl train-control :metric \"kappa\"\n         :tuneGrid (expand-grid :C (range 0.01 0.125 0.025))))\n\nView final model\n\n($ svm-linear 'finalModel)\n\n\nSupport Vector Machine object of class \"ksvm\" \n\nSV type: C-svc  (classification) \n parameter : cost C = 0.035 \n\nLinear (vanilla) kernel function. \n\nNumber of Support Vectors : 57 \n\nObjective Function Value : -1.7603 \nTraining error : 0.072464 \n\n\n\n(comment\n  (def plot-svm-linear\n    (r.e1071/svm '(formula mpg.cat (- . mpg))\n                 :data (tc/convert-types r-data \"mpg.cat\" :int32)\n                 :kernel \"linear\" :cost 0.01)))\n\n\n3.2.1 Cross-validation errors\n\n($ svm-linear 'results)\n\n\n      C  Accuracy     Kappa AccuracySD    KappaSD\n1 0.010 0.9171101 0.8332584 0.01775988 0.03560476\n2 0.035 0.9174666 0.8339890 0.02033831 0.04088029\n3 0.060 0.9173710 0.8337879 0.02270234 0.04575695\n4 0.085 0.9126572 0.8243661 0.02194878 0.04390802\n5 0.110 0.9116561 0.8222342 0.02235704 0.04485107\n\n\nI measured the goodness-of-fit versus errors. For each C, R built 20 bootstraped linear SVM models. The best Kappa per C is reported. Based on Kappa, \\(C = 0.035\\) is best.\n\nNow repeat (b), this time using SVMs with radial and polynomial basis kernels, with different values of gamma and degree and C. Comment on your results.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ISLP Ch9 Q7</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_7.html#svm-radial-and-polynomial",
    "href": "assignment.islp_9_7.html#svm-radial-and-polynomial",
    "title": "3  ISLP Ch9 Q7",
    "section": "3.3 SVM radial and polynomial",
    "text": "3.3 SVM radial and polynomial\n\n3.3.1 svmRadial\n\n(RNGkind :sample.kind \"Rounding\")\n\n\n[1] \"Mersenne-Twister\" \"Inversion\"        \"Rounding\"        \n\n\n\n(set-seed 0)\n\n\nNULL\n\n\nHyperparameter check\n\n(modelLookup \"svmRadial\")\n\n\n      model parameter label forReg forClass probModel\n1 svmRadial     sigma Sigma   TRUE     TRUE      TRUE\n2 svmRadial         C  Cost   TRUE     TRUE      TRUE\n\n\nBuild model\n\n(def svm-radial\n  (train '(formula mpg.cat (- . mpg))\n         :data training-data :method \"svmRadial\" :trControl train-control\n         :metric \"kappa\"\n         :tuneGrid (tc/dataset\n                     (grid/sobol-gridsearch\n                       {:C     (grid/linear 0.25 150 8)\n                        :sigma (grid/linear 0.000001 0.00001 5)}))))\n\nView final model\n\n($ svm-radial 'finalModel)\n\n\nSupport Vector Machine object of class \"ksvm\" \n\nSV type: C-svc  (classification) \n parameter : cost C = 150 \n\nGaussian Radial Basis kernel function. \n Hyperparameter : sigma =  1e-05 \n\nNumber of Support Vectors : 64 \n\nObjective Function Value : -5873.092 \nTraining error : 0.039855 \n\n\n\n(comment\n  (def plot-svm-radial\n    (r.e1071/svm '(formula mpg.cat (- . mpg))\n                 :data (tc/convert-types r-data \"mpg.cat\" :int32)\n                 :kernel \"radial\" :cost 107.214285714286 :sigma 3.25e-06)))\n\n\n\n3.3.2 Cross-validation errors\n\n($ svm-radial 'results)\n\n\n           C    sigma  Accuracy     Kappa AccuracySD    KappaSD\n1    0.25000 1.00e-06 0.8833750 0.7656933 0.02474869 0.04959927\n6   21.64286 1.00e-06 0.8901821 0.7794242 0.02189154 0.04388273\n11  43.03571 1.00e-06 0.8920549 0.7831918 0.02473057 0.04941727\n16  64.42857 1.00e-06 0.8935104 0.7860984 0.02644102 0.05270203\n21  85.82143 1.00e-06 0.8944305 0.7879690 0.02549771 0.05071660\n26 107.21429 1.00e-06 0.8959157 0.7909338 0.02456325 0.04906032\n31 128.60714 1.00e-06 0.8969336 0.7929813 0.02504592 0.05000107\n36 150.00000 1.00e-06 0.8984212 0.7959607 0.02488068 0.04971731\n2    0.25000 3.25e-06 0.8847289 0.7683157 0.02244202 0.04541825\n7   21.64286 3.25e-06 0.8974278 0.7940053 0.02429315 0.04837000\n12  43.03571 3.25e-06 0.8941426 0.7874291 0.02359858 0.04706370\n17  64.42857 3.25e-06 0.8965624 0.7922130 0.02282044 0.04542483\n22  85.82143 3.25e-06 0.8974051 0.7938333 0.02347745 0.04706646\n27 107.21429 3.25e-06 0.8964420 0.7919512 0.02409085 0.04837719\n32 128.60714 3.25e-06 0.8949473 0.7889674 0.02409934 0.04849591\n37 150.00000 3.25e-06 0.8964737 0.7920664 0.02448085 0.04912228\n3    0.25000 5.50e-06 0.8852682 0.7694862 0.02442095 0.04904901\n8   21.64286 5.50e-06 0.8941408 0.7874105 0.02386209 0.04764312\n13  43.03571 5.50e-06 0.8949784 0.7889673 0.02704639 0.05416533\n18  64.42857 5.50e-06 0.8929821 0.7850209 0.02624850 0.05269261\n23  85.82143 5.50e-06 0.8944339 0.7879447 0.02578807 0.05175839\n28 107.21429 5.50e-06 0.8934026 0.7858215 0.02374042 0.04766020\n33 128.60714 5.50e-06 0.8968897 0.7927721 0.02607739 0.05246945\n38 150.00000 5.50e-06 0.9003425 0.7997520 0.02857987 0.05747702\n4    0.25000 7.75e-06 0.8856591 0.7703052 0.02281895 0.04614578\n9   21.64286 7.75e-06 0.8930841 0.7852677 0.02436272 0.04873047\n14  43.03571 7.75e-06 0.8929078 0.7849590 0.02838410 0.05704814\n19  64.42857 7.75e-06 0.8954140 0.7900840 0.02544598 0.05083392\n24  85.82143 7.75e-06 0.8969092 0.7930197 0.02787478 0.05573365\n29 107.21429 7.75e-06 0.9029020 0.8049847 0.02936503 0.05871301\n34 128.60714 7.75e-06 0.9064132 0.8120334 0.02916810 0.05820951\n39 150.00000 7.75e-06 0.9060271 0.8112559 0.03078577 0.06134504\n5    0.25000 1.00e-05 0.8875706 0.7741968 0.02488036 0.05014435\n10  21.64286 1.00e-05 0.8924980 0.7840832 0.02836727 0.05711738\n15  43.03571 1.00e-05 0.8939510 0.7871905 0.02735880 0.05474495\n20  64.42857 1.00e-05 0.8980007 0.7952439 0.02905157 0.05803917\n25  85.82143 1.00e-05 0.9010134 0.8012216 0.02900648 0.05780814\n30 107.21429 1.00e-05 0.9058099 0.8106791 0.02781523 0.05558962\n35 128.60714 1.00e-05 0.9078532 0.8147551 0.02702958 0.05401028\n40 150.00000 1.00e-05 0.9093257 0.8176629 0.02677906 0.05357765\n\n\nMuch bigger grid to search through. A plot would make this easier.\n\n\n3.3.3 svmRadial\n\n(RNGkind :sample.kind \"Rounding\")\n\n\n[1] \"Mersenne-Twister\" \"Inversion\"        \"Rounding\"        \n\n\n\n(set-seed 0)\n\n\nNULL\n\n\nHyperparameter check\n\n(modelLookup \"svmPoly\")\n\n\n    model parameter             label forReg forClass probModel\n1 svmPoly    degree Polynomial Degree   TRUE     TRUE      TRUE\n2 svmPoly     scale             Scale   TRUE     TRUE      TRUE\n3 svmPoly         C              Cost   TRUE     TRUE      TRUE\n\n\nBuild model\n\n(comment\n  ;too much time\n  (def svm-poly\n    (train '(tilde mpg.cat\n                   (+ cylinders displacement horsepower weight\n                      acceleration year origin name))\n           :data training-data :method \"svmPoly\"\n           :trControl train-control :metric \"kappa\"\n           :tuneGrid (tc/dataset\n                       (take 6\n                             (grid/sobol-gridsearch\n                               {:C      (grid/linear 0.25 2 5)\n                                :scale  (grid/linear 0.001 1 5)\n                                :degree (grid/linear 1 2 2 :int16)})))))\n  ;=&gt; Support Vector Machine object of class \"ksvm\"\n  ;\n  ;SV type: C-svc  (classification)\n  ; parameter : cost C = 1.5625\n  ;\n  ;Polynomial kernel function.\n  ; Hyperparameters : degree =  1  scale =  0.001  offset =  1\n  ;\n  ;Number of Support Vectors : 78\n  ;\n  ;Objective Function Value : -113.7188\n  ;Training error : 0.094203\n  ($ svm-poly 'finalModel))\n\n\n(def svm-poly\n  (train '(tilde mpg.cat\n                 (+ cylinders displacement horsepower weight\n                    acceleration year origin name))\n         :data training-data :method \"svmPoly\"\n         :trControl train-control :metric \"kappa\"\n         :tuneGrid (tc/dataset\n                     {:C      1.5625\n                      :scale  0.001\n                      :degree 1})))\n\nView final model\n\n($ svm-poly 'finalModel)\n\n\nSupport Vector Machine object of class \"ksvm\" \n\nSV type: C-svc  (classification) \n parameter : cost C = 1.5625 \n\nPolynomial kernel function. \n Hyperparameters : degree =  1  scale =  0.001  offset =  1 \n\nNumber of Support Vectors : 72 \n\nObjective Function Value : -97.6261 \nTraining error : 0.068841 \n\n\n\n(def plot-svm-poly\n  (r.e1071/svm '(formula mpg.cat (- . mpg))\n               :data (tc/convert-types r-data \"mpg.cat\" :int32)\n               :kernel \"polynomial\" :cost 1.5625 :degree 1 :scale 0.001))\n\n\n(-&gt; (plot plot-svm-poly\n          :data (-&gt; (r-&gt;clj test-data)\n                    (tc/drop-columns [:$row.names :mpg.cat])\n                    clj-&gt;r)\n          :formula '(tilde displacement weight))\n    plot-&gt;svg)\n\n\n\"&lt;?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?&gt;\\n&lt;svg xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" width=\\\"504pt\\\" height=\\\"504pt\\\" viewBox=\\\"0 0 504 504\\\" version=\\\"1.1\\\"&gt;\\n&lt;g id=\\\"surface51\\\"&gt;\\n&lt;/g&gt;\\n&lt;/svg&gt;\\n\"\n\n\n(predict plot-svm-poly test-data)\n\n\n           5            6            8           12           14           20 \n 0.093884149 -0.127112610 -0.131835504  0.049035557 -0.032607662  0.924874267 \n          21           26           27           31           32           33 \n 0.834702676 -0.105369698 -0.032008226  0.821960241  0.936184818  0.466043634 \n          36           37           41           42           44           49 \n 0.379219163  0.386469818  0.013184390 -0.138358203 -0.175490237  0.851458132 \n          50           54           57           64           68           69 \n 0.906968346  1.022571797  0.930562366  0.015408963 -0.054924619 -0.051095613 \n          70           74           75           77           80           89 \n-0.098763838  0.003993701  0.016675792  0.848765335  0.828472930  0.059221205 \n          92          103          110          122          131          132 \n-0.034464354 -0.145905014  0.924478938  0.860436102  0.809709438  0.345093379 \n         133          136          137          138          145          153 \n 0.338051352 -0.061735951 -0.003350196 -0.014457039  0.922986143  0.378869456 \n         154          161          163          169          170          171 \n 0.410483645  0.332180080  0.456533639  0.811218804  0.901909615  0.946270965 \n         182          186          188          190          191          203 \n 0.927932948  0.050253581  0.068373214  0.448578887  0.411629347  1.016574970 \n         207          210          211          212          215          218 \n 0.064555419  0.477481333 -0.010333697  0.029146410  1.000284833  0.885044006 \n         227          233          234          240          241          243 \n 0.389889148  0.810420481  0.978950707  0.661027498  0.897052642  0.975836541 \n         244          247          250          251          258          259 \n 0.975490065  1.049862920  0.138400085  0.414194856  0.506510673  0.410251753 \n         262          265          269          273          276          278 \n 0.437350089  0.937877037  0.932893313  0.749171232  0.542348367  1.007347573 \n         280          281          285          292          294          295 \n 0.516670389  0.812230956  0.130105504  1.018648857  0.969676602  0.869772023 \n         296          298          303          304          307          309 \n 0.625985431  0.797638595  0.993188346  0.833773811  0.859628851  1.042122501 \n         310          313          319          320          321          322 \n 0.961846507  0.824304116  0.974988178  1.005300592  1.033585316  0.833026766 \n         324          325          326          327          335          337 \n 0.981389405  0.949713970  0.758088054  0.805468928  0.889552575  0.856759240 \n         339          344          346          349          354          355 \n 0.911943366  1.049921033  1.054456363  0.917688704  0.951089412  0.824438769 \n         356          357          361          367          376          381 \n 0.609667603  0.673222268  0.530197905  0.890472147  1.031906582  0.573524557 \n         384          389 \n 0.535200332  0.973548498 \n\n\n\n\n3.3.4 Cross-validation errors\n\n($ svm-poly 'results)\n\n\n       C scale degree  Accuracy    Kappa AccuracySD    KappaSD\n1 1.5625 0.001      1 0.9051167 0.809254 0.02522795 0.05062125\n\n\n\nMake some plots to back up your assertions in (b) and (c).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ISLP Ch9 Q7</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_7.html#plots",
    "href": "assignment.islp_9_7.html#plots",
    "title": "3  ISLP Ch9 Q7",
    "section": "3.4 Plots",
    "text": "3.4 Plots\n\n^kind/html\n(-&gt; (plot svm-linear :metric \"Kappa\")\n    plot-&gt;svg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n\n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n^kind/html\n(comment\n  (-&gt; (r.kernlab/plot ($ svm-linear 'finalModel)\n                      :data (-&gt; (r-&gt;clj test-data)\n                                (tc/drop-columns [:$row.names :mpg :mpg.cat])\n                                clj-&gt;r)\n                      :formula '(formula displacement weight)\n                      :slice {'displacement 2 'weight 4})\n      plot-&gt;svg))\n\nAccording to our text, we could use &gt; plot(svmfit, dat, x1 ∼ x4) to plot. I was unsuccessful.\n\n^kind/html\n(-&gt; (plot plot-svm-poly\n          :data test-data\n          :formula '(formula displacement weight))\n    plot-&gt;svg)\n\n\n\n\n\n\n\nBut predict works.\n\n(predict plot-svm-poly test-data)\n\n\n           5            6            8           12           14           20 \n 0.093884149 -0.127112610 -0.131835504  0.049035557 -0.032607662  0.924874267 \n          21           26           27           31           32           33 \n 0.834702676 -0.105369698 -0.032008226  0.821960241  0.936184818  0.466043634 \n          36           37           41           42           44           49 \n 0.379219163  0.386469818  0.013184390 -0.138358203 -0.175490237  0.851458132 \n          50           54           57           64           68           69 \n 0.906968346  1.022571797  0.930562366  0.015408963 -0.054924619 -0.051095613 \n          70           74           75           77           80           89 \n-0.098763838  0.003993701  0.016675792  0.848765335  0.828472930  0.059221205 \n          92          103          110          122          131          132 \n-0.034464354 -0.145905014  0.924478938  0.860436102  0.809709438  0.345093379 \n         133          136          137          138          145          153 \n 0.338051352 -0.061735951 -0.003350196 -0.014457039  0.922986143  0.378869456 \n         154          161          163          169          170          171 \n 0.410483645  0.332180080  0.456533639  0.811218804  0.901909615  0.946270965 \n         182          186          188          190          191          203 \n 0.927932948  0.050253581  0.068373214  0.448578887  0.411629347  1.016574970 \n         207          210          211          212          215          218 \n 0.064555419  0.477481333 -0.010333697  0.029146410  1.000284833  0.885044006 \n         227          233          234          240          241          243 \n 0.389889148  0.810420481  0.978950707  0.661027498  0.897052642  0.975836541 \n         244          247          250          251          258          259 \n 0.975490065  1.049862920  0.138400085  0.414194856  0.506510673  0.410251753 \n         262          265          269          273          276          278 \n 0.437350089  0.937877037  0.932893313  0.749171232  0.542348367  1.007347573 \n         280          281          285          292          294          295 \n 0.516670389  0.812230956  0.130105504  1.018648857  0.969676602  0.869772023 \n         296          298          303          304          307          309 \n 0.625985431  0.797638595  0.993188346  0.833773811  0.859628851  1.042122501 \n         310          313          319          320          321          322 \n 0.961846507  0.824304116  0.974988178  1.005300592  1.033585316  0.833026766 \n         324          325          326          327          335          337 \n 0.981389405  0.949713970  0.758088054  0.805468928  0.889552575  0.856759240 \n         339          344          346          349          354          355 \n 0.911943366  1.049921033  1.054456363  0.917688704  0.951089412  0.824438769 \n         356          357          361          367          376          381 \n 0.609667603  0.673222268  0.530197905  0.890472147  1.031906582  0.573524557 \n         384          389 \n 0.535200332  0.973548498 \n\n\n\n(comment\n  (-&gt; (r-&gt;clj test-data)\n      (tc/drop-columns [:$row.names :mpg.cat])\n      clj-&gt;r))\n\n\n3.4.0.1 SVM Radial\n\n^kind/html\n(-&gt; (plot svm-radial :metric \"Kappa\")\n    plot-&gt;svg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n\n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n\n\n\n\n  \n\n\n  \n  \n\n\n  \n  \n  \n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n^kind/html\n(-&gt; (plot svm-radial :metric \"Kappa\" :plotType \"level\")\n    plot-&gt;svg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n\n\n\n\n3.4.0.2 SVM Polynomial\nThis model took the longest to train. Having 5 sets of hyperparameters added two minutes to rendering. If I ran the full commented out :tuneGrid, the following three plots will view accuracy measures, like the above plots. But with one data we have:\n\n^kind/html\n(-&gt; (ggplot :data ($ svm-poly 'results)\n            (aes :x 'C :y 'Kappa :color '(factor scale)))\n    (r+ (geom_point)\n        (geom_line)\n        (facet_wrap '(formula nil degree))\n        (theme_bw))\n    plot-&gt;svg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n  \n  \n  \n  \n\n\n\n\n\n\n\n  \n\n\n  \n  \n  \n  \n  \n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n\n\n\n(comment\n  ^kind/html\n  (-&gt; (plot svm-poly :metric \"Kappa\")\n      plot-&gt;svg)\n\n  ^kind/html\n  (-&gt; (plot svm-poly :metric \"Kappa\" :plotType \"level\")\n      plot-&gt;svg))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ISLP Ch9 Q7</span>"
    ]
  },
  {
    "objectID": "assignment.islp_9_7.html#evaluate-model",
    "href": "assignment.islp_9_7.html#evaluate-model",
    "title": "3  ISLP Ch9 Q7",
    "section": "3.5 Evaluate model",
    "text": "3.5 Evaluate model\n\n(defn eval-list [model]\n  (let [pred (predict model test-data)\n        obs (factor ($ test-data 'mpg.cat))\n        df (data-frame :pred pred :obs obs)\n        ds (defaultSummary df :lev (levels (factor ($ test-data 'mpg.cat))))\n        tcs (twoClassSummary df :lev (levels (factor ($ test-data 'mpg.cat))))]\n    (append ds tcs)))\n\n\n(eval-list svm-linear)\n\n\n Accuracy     Kappa       ROC      Sens      Spec \n0.8620690 0.7241379        NA 0.8103448 0.9137931 \n\n\n\n(eval-list svm-radial)\n\n\n Accuracy     Kappa       ROC      Sens      Spec \n0.8706897 0.7413793        NA 0.8275862 0.9137931 \n\n\n\n(eval-list svm-poly)\n\n\n Accuracy     Kappa       ROC      Sens      Spec \n0.8706897 0.7413793        NA 0.8448276 0.8965517 \n\n\nPolynomial model preformed best. Turns out, the best was degree 1, so linear. Then linear itself.\n\nsource: src/assignment/islp_9_7.clj",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ISLP Ch9 Q7</span>"
    ]
  }
]